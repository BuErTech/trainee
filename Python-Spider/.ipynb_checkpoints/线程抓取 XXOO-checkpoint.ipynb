{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import threading\n",
    "import hashlib \n",
    "import math\n",
    "import lxml\n",
    " \n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:61.0) Gecko/20100101 Firefox/61.0'}\n",
    " \n",
    "# 解析加密img图片的方法,返回真实imgurl地址列表\n",
    "def parse_img_url(pages):\n",
    "    print('parse_img_url start')\n",
    "    real_img_url = []  # 真实img地址\n",
    "    for i in pages:\n",
    "        # 使用BeautifulSoup解析为xml形式,方便查找html节点\n",
    "        soup = BeautifulSoup(i, 'lxml')\n",
    "        # 根据class属性值查找加密的imgurl所在\n",
    "        imgurl = soup.find_all(class_='img-hash')\n",
    "        for j in imgurl:\n",
    "            # 转为真实地址\n",
    "            url=j.text\n",
    "            url = base64.b64decode(url).decode('utf-8')\n",
    "            real_img_url.append(url)\n",
    "            print(url+'parse_img_url end')\n",
    "    return real_img_url\n",
    " \n",
    " \n",
    "# 下载图片的方法\n",
    "# suffix和url_dase64是为了命名而存在\n",
    "def downloadimg(url, header):\n",
    "    print('download img start',url)\n",
    "    # 利用hashlib生成文件名\n",
    "    md5 = hashlib.md5()\n",
    "    md5.update(url.encode('utf-8'))\n",
    "    filename = md5.hexdigest()\n",
    "    print('filename:',filename,'\\n','type;',type(filename))\n",
    "    # 补全url\n",
    "    url = 'http:' + url\n",
    "    # 提取文件后缀\n",
    "    suffix = url.split('.')\n",
    "    suffix = suffix[len(suffix) - 1]\n",
    " \n",
    "    # 抓取页面\n",
    "    response = requests.get(url, header)\n",
    "    img = response.content\n",
    "    with open('.//jiandan//' +filename + '.' + suffix, 'wb') as f:\n",
    "        print('.//jiandan//' +filename + '.' + suffix)\n",
    "        f.write(json.dumps(content, ensure_ascii=False) + '\\n')\n",
    "    print('下载成功')\n",
    " \n",
    " \n",
    "# 自定义线程类\n",
    "class Spider(threading.Thread):\n",
    "    print('main.header:',header)\n",
    "    count=1\n",
    "    def __init__(self, pages):\n",
    "        threading.Thread.__init__(self)  # 初始化线程\n",
    "        self.pages = pages\n",
    "        print('创建线程',Spider.count)\n",
    "        Spider.count+=1\n",
    " \n",
    "    def run(self):\n",
    "        real_img_url = parse_img_url(self.pages)\n",
    "        # 下载图片\n",
    "        for url in real_img_url:\n",
    "            downloadimg(url, header)\n",
    " \n",
    " \n",
    "# 主程序\n",
    "def main(amount):\n",
    "    print('main start')\n",
    " \n",
    "    # 当前页面\n",
    "    current_url = 'http://jandan.net/ooxx'\n",
    " \n",
    "    \"\"\"\n",
    "    多线程抓取页面\n",
    "    \"\"\"\n",
    "    pages = []  # 所有待抓取页面\n",
    "    threads = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
