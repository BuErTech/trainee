{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这次要抓取的目标是[豆瓣电影 TOP250](https://movie.douban.com/top250)，主要是要的是 BeautifulSoup，一道美味的汤啊~ 🍵\n",
    "\n",
    "# [](https://hoxis.github.io/python-douban-top250.html#%E8%A7%A3%E6%9E%90 \"解析\")解析\n",
    "\n",
    "其实简单的网络爬虫无外乎查看网页源码，从源码中获取自己想要的东西，然后对其进行处理。\n",
    "\n",
    "[![豆瓣电影 Top 250](https://www.github.com/hoxis/token4md/raw/master/1528077947010.jpg)](https://www.github.com/hoxis/token4md/raw/master/1528077947010.jpg)\n",
    "\n",
    "通过查看页面元素代码可以看出：\n",
    "\n",
    "1.  电影条目是被 `<ol class=\"grid_view\">` 所包围的；\n",
    "2.  其中每个电影条目是一个 `<li>`；\n",
    "3.  另外，每页有 25 个条目，共 10 页，这意味着需要解析多页数据。\n",
    "\n",
    "我们来看下其中一个条目的源码：\n",
    "\n",
    "```html\n",
    "\n",
    "    <li>  \n",
    "    \t<div class=\"item\">  \n",
    "    \t\t<div class=\"pic\">  \n",
    "    \t\t\t<em class=\"\">1</em>  \n",
    "    \t\t\t<a href=\"https://movie.douban.com/subject/1292052/\">  \n",
    "    \t\t\t\t<img width=\"100\" alt=\"肖申克的救赎\" src=\"https://img3.doubanio.com/view/photo/s_ratio_poster/public/p480747492.webp\" class=\"\"></a>  \n",
    "    \t\t</div>  \n",
    "    \t\t<div class=\"info\">  \n",
    "    \t\t\t<div class=\"hd\">  \n",
    "    \t\t\t\t<a href=\"https://movie.douban.com/subject/1292052/\" class=\"\">  \n",
    "    \t\t\t\t\t<span class=\"title\">肖申克的救赎</span>  \n",
    "    \t\t\t\t\t<span class=\"title\">&nbsp;/&nbsp;The Shawshank Redemption</span>  \n",
    "    \t\t\t\t\t<span class=\"other\">&nbsp;/&nbsp;月黑高飞(港) / 刺激1995(台)</span></a>  \n",
    "    \t\t\t\t<span class=\"playable\">[可播放]</span></div>  \n",
    "    \t\t\t<div class=\"bd\">  \n",
    "    \t\t\t\t<p class=\"\">导演: 弗兰克·德拉邦特 Frank Darabont&nbsp;&nbsp;&nbsp;主演: 蒂姆·罗宾斯 Tim Robbins /...  \n",
    "    \t\t\t\t\t<br>1994&nbsp;/&nbsp;美国&nbsp;/&nbsp;犯罪 剧情</p>  \n",
    "    \t\t\t\t<div class=\"star\">  \n",
    "    \t\t\t\t\t<span class=\"rating5-t\"></span>  \n",
    "    \t\t\t\t\t<span class=\"rating_num\" property=\"v:average\">9.6</span>  \n",
    "    \t\t\t\t\t<span property=\"v:best\" content=\"10.0\"></span>  \n",
    "    \t\t\t\t\t<span>1041580人评价</span></div>  \n",
    "    \t\t\t\t<p class=\"quote\">  \n",
    "    \t\t\t\t\t<span class=\"inq\">希望让人自由。</span></p>  \n",
    "    \t\t\t\t<p>  \n",
    "    \t\t\t\t\t<span class=\"gact\">  \n",
    "    \t\t\t\t\t\t<a href=\"https://movie.douban.com/wish/50494322/update?add=1292052\" target=\"_blank\" class=\"j a_collect_btn\" name=\"sbtn-1292052-wish\" rel=\"nofollow\">想看</a></span>&nbsp;&nbsp;</p>  \n",
    "    \t\t\t</div>  \n",
    "    \t\t</div>  \n",
    "    \t</div>  \n",
    "    </li>  \n",
    "    </pre>\n",
    "```\n",
    "\n",
    "对于每个条目，我们需要解析出其中的 电影名称、评分、评价人数，及一句话点评。\n",
    "\n",
    "## [](https://hoxis.github.io/python-douban-top250.html#%E6%A0%87%E9%A2%98%E3%80%81%E8%AF%84%E5%88%86%E3%80%81%E8%AF%84%E4%BB%B7%E8%A7%A3%E6%9E%90 \"标题、评分、评价解析\")标题、评分、评价解析\n",
    "\n",
    "标题是在 `肖申克的救赎` 里的，我们可以使用\n",
    "\n",
    "```\n",
    "    find(\"span\", attrs={\"class\": \"title\"}).getText()  \n",
    "```\n",
    "\n",
    "获取到，但是明显这里又多个 `<span class=\"title\">`，那我们就只获取第一个，其他的不关心。\n",
    "\n",
    "评分和评价的解析和标题类似，用同一种解析方法解析即可。\n",
    "\n",
    "## [](https://hoxis.github.io/python-douban-top250.html#%E8%AF%84%E4%BB%B7%E4%BA%BA%E6%95%B0%E8%A7%A3%E6%9E%90 \"评价人数解析\")评价人数解析\n",
    "\n",
    "评价人数这里是这样的： `1041580人评价`，明显跟上面的不同，它没有 class 属性，这里只能通过 text 来查找了：\n",
    "\n",
    "```\n",
    "    find(text=re.compile('人评价$'))  \n",
    "```\n",
    "\n",
    "这里用了正则表达式来进行匹配，即匹配以 `人评价` 结尾的文本。\n",
    "\n",
    "## [](https://hoxis.github.io/python-douban-top250.html#%E4%B8%8B%E4%B8%80%E9%A1%B5%E8%A7%A3%E6%9E%90 \"下一页解析\")下一页解析\n",
    "\n",
    "```\n",
    "    <span class=\"next\">  \n",
    "        <link rel=\"next\" href=\"?start=25&amp;filter=\"/>  \n",
    "        <a href=\"?start=25&amp;filter=\" >后页&gt;</a>  \n",
    "    </span>  \n",
    "```\n",
    "\n",
    "对照代码，需要从中解析出下一页的连接 `?start=25&amp;filter=`。\n",
    "\n",
    "解析方法类似于标题的解析，先解析出 `<span class=\"next\">`，然后解析其中的 `<a>` 标签。\n",
    "\n",
    "```\n",
    "    find(\"span\", attrs={\"class\":\"next\"}).find(\"a\")  \n",
    "```\n",
    "\n",
    "要解析的东西基本上就是这些，最后需要将解析结果保存到文件。\n",
    "\n",
    "# [](https://hoxis.github.io/python-douban-top250.html#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81 \"实现代码\")实现代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding:utf-8\n",
    "\n",
    "import requests, re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def download_page(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    return soup\n",
    "\n",
    "def parse_soup(soup):\n",
    "    return_list = []\n",
    "    # 利用 class 属性找到 grid\n",
    "    grid = soup.find(\"ol\", attrs={\"class\": \"grid_view\"})\n",
    "    # 不加 attrs= 也可以\n",
    "    # grid = soup.find(\"ol\", {\"class\": \"grid_view\"})\n",
    "    if grid:\n",
    "        # 利用标签获取 list\n",
    "        movie_list = grid.find_all(\"li\")\n",
    "\n",
    "        # 遍历 list\n",
    "        for movie in movie_list:\n",
    "            # 一个电影有多个名字，这里只取第一个\n",
    "            # getText() 方法获取到值\n",
    "            title = movie.find(\"span\", attrs={\"class\": \"title\"}).getText()\n",
    "            # print(title)\n",
    "            rating_num = movie.find(\"span\", attrs={\"class\": \"rating_num\"}).getText()\n",
    "            inq = movie.find(\"span\", attrs={\"class\": \"inq\"})\n",
    "            # 利用 text 配合正则表达式匹配搜索文本\n",
    "            rating_p = soup.find(text=re.compile('人评价$'))\n",
    "            # 有些暂时没有一句话评论\n",
    "            if not inq:\n",
    "                inq = \"暂无\"\n",
    "            else:\n",
    "                inq = inq.getText()\n",
    "            return_list.append(title + \"，\" + rating_p + \"，评分：\" + rating_num + \"，一句话评价：\" + inq)\n",
    "\n",
    "        next_page = soup.find(\"span\", attrs={\"class\":\"next\"}).find(\"a\")\n",
    "        if next_page:\n",
    "            return return_list, next_page[\"href\"]\n",
    "        else:\n",
    "            return return_list, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://movie.douban.com/top250\"\n",
    "    next_url = \"\"\n",
    "    # 将结果保存到文件\n",
    "    with open(\"doubanMoviesTop250.txt\",\"w+\") as f: \n",
    "        while next_url or next_url == \"\":\n",
    "            soup = download_page(url + next_url)\n",
    "            movie_list, next_url = parse_soup(soup)\n",
    "            # 将 list 拆分成不同行\n",
    "            f.write(\"\\n\".join(movie_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://ww3.sinaimg.cn/large/006tNc79ly1g53v4gz6x6j315m0ss4bz.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
