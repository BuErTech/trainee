{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# newocr\n",
    "\n",
    "https://www.newocr.com/\n",
    "\n",
    "\n",
    "# A comprehensive guide to OCR with Tesseract, OpenCV and Python\n",
    "\n",
    "https://nanonets.com/blog/ocr-with-tesseract/\n",
    "\n",
    "\n",
    "\n",
    "# Python计算字符串相似度\n",
    "\n",
    "## [<svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg>](https://github.com/coding-fans/python-book/blob/master/docs/zh_CN/practices/string-similarity.rst#%E8%83%8C%E6%99%AF)背景\n",
    "\n",
    "有个任务需要从多个系统取出工单信息进行处理，\n",
    "但是工单只有一个标题可以关联，而且还不是严格相等的。\n",
    "例如：\n",
    "\n",
    "* 易查通日常升级的发布请示\n",
    "* 【易查通】易查通系统日常升级\n",
    "\n",
    "这种判断比较棘手，只能利用 **字符串相似度** 进行衡量：\n",
    "\n",
    "<pre>\n",
    "ifsimilarity('易查通日常升级的发布请示', '【易查通】易查通系统日常升级') > 0.5:\n",
    "    print('哥俩是同个工单')\n",
    "</pre>\n",
    "\n",
    "那么， Python 有现成的类库可衡量字符串相似度么？\n",
    "\n",
    "## [<svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path></svg>](https://github.com/coding-fans/python-book/blob/master/docs/zh_CN/practices/string-similarity.rst#difflib)difflib\n",
    "\n",
    "基于 [difflib.SequenceMatcher](https://docs.python.org/2/library/difflib.html#difflib.SequenceMatcher) 类，我们可以实现一个用于计算字符串相似度的函数：\n",
    "\n",
    "<pre>\n",
    "fromdifflib import SequenceMatcher\n",
    "\n",
    "def similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "</pre>\n",
    "\n",
    "ratio 方法返回一个系数，衡量两个字符串的相识度，取值在 0-1 之间。\n",
    "\n",
    "如果两个字符串完全相同，则系数为 1.0 ：\n",
    "\n",
    "<pre>\n",
    ">>> similarity('fasionchan', 'fasionchan')\n",
    "1.0\n",
    "</pre>\n",
    "\n",
    "如果两个字符串完全没有任何相同之处，则系数为 0.0 ：\n",
    "\n",
    "<pre>\n",
    ">>> similarity('fasionchan', '')\n",
    "0.0\n",
    ">>> similarity('aaaaaaaa', 'bbbbbbbb')\n",
    "0.0\n",
    "</pre>\n",
    "\n",
    "其他情况则介于 0 与 1 之间，越接近 1 越相似：\n",
    "\n",
    "<pre>\n",
    ">>> similarity('apple', 'banana')\n",
    "0.18181818181818182\n",
    ">>> similarity('易查通日常升级的发布请示', '【易查通】易查通系统日常升级')\n",
    "0.5384615384615384\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity('fasionchan', 'fasionchan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity('fasionchan', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity('aaaaaaaa', 'bbbbbbbb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18181818181818182"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity('apple', 'banana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5384615384615384"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity('易查通日常升级的发布请示', '【易查通】易查通系统日常升级')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9523809523809523\n",
      "1.0\n",
      "0.8181818181818182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 第一个参数是想要忽略的字符，可以不算在其中。 seq = difflib.SequenceMatcher(lambda x:x=\" \", a, b) '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import difflib\n",
    "query_str = 'as of date 11/12/2019'\n",
    "s1 = 'as of data 11/12/2019'\n",
    "s2 = 'as fo date 11/12/2019'\n",
    "s3 = 'similar date 11/12/2019'\n",
    "print(difflib.SequenceMatcher(None, query_str, s1).quick_ratio()) # 0.9523809523809523 \n",
    "print(difflib.SequenceMatcher(None, query_str, s2).quick_ratio()) # 1.0 \n",
    "print(difflib.SequenceMatcher(None, query_str, s3).quick_ratio()) # 0.8181818181818182 \n",
    "\"\"\" 第一个参数是想要忽略的字符，可以不算在其中。 seq = difflib.SequenceMatcher(lambda x:x=\" \", a, b) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://www.cnpython.com/pypi/strsim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fuzzywuzzy\n",
    "\n",
    "fuzzywuzzy 是一个第三方库，提供了更多的方法进行不同的字符匹配需求。\n",
    "\n",
    "可以看到 fuzzywuzzy 的默认匹配区分度更直观点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "95\n",
      "77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lw/anaconda3/lib/python3.6/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "query_str = 'as of date 11/12/2019'\n",
    "s1 = 'as of data 11/12/2019'\n",
    "s2 = 'as fo date 11/12/2019'\n",
    "s3 = 'similar date 11/12/2019'\n",
    "\n",
    "print (fuzz.ratio(query_str, s1)) #95 \n",
    "print (fuzz.ratio(query_str, s2)) #95 \n",
    "print (fuzz.ratio(query_str, s3)) #77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除些外，还有 partial_ratio(), token_set_ratio(),partial_token_sort_ratio()等方法。\n",
    "\n",
    "本文内容基本来源于这篇文章，这里存一下我的笔记：\n",
    "\n",
    "https://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/\n",
    "\n",
    "\n",
    "## 全局匹配和子字符串匹配\n",
    "\n",
    "先看对ice和icecream两个字符串的处理：\n",
    "\n",
    "```language-python\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "str1 = \"ice\"\n",
    "str2 = \"icecream\"\n",
    "\n",
    "print (fuzz.ratio(str1, str2))\n",
    "# 55\n",
    "print (fuzz.partial_ratio(str1, str2))\n",
    "# 100\n",
    "123456789\n",
    "```\n",
    "\n",
    "从形式上看，icecream比ice在**末尾**多了几个字符，或者说ice是icecream的子字符串，但其实它们是两个东西。ratio()判断不相似，而partial_ratio()做得不够好，它认为两者是完全等同的。\n",
    "\n",
    "```language-python\n",
    "str1 = \"ice-cream\"\n",
    "str2 = \"icecream\"\n",
    "\n",
    "print (fuzz.ratio(str1, str2))\n",
    "# 94\n",
    "print (fuzz.partial_ratio(str1, str2))\n",
    "# 88\n",
    "1234567\n",
    "```\n",
    "\n",
    "\n",
    "这个例子的结果相反，对于相同的两样东西“ice-cream”和\"icecream\"，partial_ratio()给出了比ratio()更低的匹配值。\n",
    "\n",
    "前面两个例子中，str1、str2长度是不等的。实际上当两个字符串**长度相等**时，ratio()和partial_ratio()给出的得分是一样的：\n",
    "\n",
    "```language-python\n",
    "str1 = \"ice-cream\"\n",
    "str2 = \"ice,cream\"\n",
    "\n",
    "print (fuzz.ratio(str1, str2))\n",
    "# 89\n",
    "print (fuzz.partial_ratio(str1, str2))\n",
    "# 89\n",
    "1234567\n",
    "```\n",
    "\n",
    "\n",
    "总结一下，对于两个**长度不同**的字符串（比如ice和icecream），partial_ratio()返回得分最高的子字符串（substring）的匹配值。对比ice和icecream，他会把icecream拆成ice, cec, cre, …等等长度和ice相等的子字符串构成的序列，再一一进行ratio()比较。\n",
    "\n",
    "在icecream中得分最高的子字符串是ice，因为ice和ice完全一样，所以最终结果是ice和ice的匹配值，即100。\n",
    "\n",
    "简单理解，如果字符串B包含了完整的字符串A，比如在icecream中包含了ice，partial_ratio()得出的匹配值就是100，无论在icecream and cheesecake and beefburger前或后面加多少吃的，结果还是100。\n",
    "\n",
    "## 打乱顺序的匹配\n",
    "\n",
    "fuzz.token_sort_ratio()用来匹配两个意思相同、但顺序不同的字符串：\n",
    "\n",
    "```language-python\n",
    "str1 = \"Tom and Jerry\"\n",
    "str2 = \"Jerry and Tom\"\n",
    "\n",
    "print (fuzz.ratio(str1, str2))\n",
    "# 38\n",
    "print (fuzz.token_sort_ratio(str1, str2))\n",
    "# 100\n",
    "1234567\n",
    "```\n",
    "\n",
    "\n",
    "ratio()对顺序敏感，而token_sort_ratio()不受单词顺序影响。\n",
    "\n",
    "token_sort_ratio()**以空格为分隔符，小写化所有字母，无视空格外的其它标点符号**，把字符串转化为“tom”, “and”, “jerry\"三个token（tokenize），按字母顺序组合成一个新的字符串“and jerry tom”，再进行普通的ratio()比较。所以“Tom and Jerry”和“Jerry and Tom”，在token_sort_ratio()眼里，都是\"and jerry tom”，最终匹配得分为100.\n",
    "\n",
    "另外还有partial_token_sort_ratio()方法，这里Tom和Tommy的partial_ratio()一样，所以整体匹配值也为100：\n",
    "\n",
    "```language-python\n",
    "str1 = \"Tom and Jerry\"\n",
    "str2 = \"Jerry and Tommy\"\n",
    "\n",
    "print (fuzz.ratio(str1, str2))\n",
    "# 43\n",
    "print (fuzz.partial_token_sort_ratio(str1, str2))\n",
    "# 100\n",
    "1234567\n",
    "```\n",
    "\n",
    "\n",
    "由于这种排序，还会发生如下情况：\n",
    "\n",
    "```language-python\n",
    "str1 = \"Tom and Jerry\"\n",
    "str2 = \"Jerry and Tom and Ana\"\n",
    "\n",
    "print (fuzz.ratio(str1, str2))\n",
    "# 47\n",
    "print (fuzz.partial_token_sort_ratio(str1, str2))\n",
    "# 100\n",
    "1234567\n",
    "```\n",
    "\n",
    "\n",
    "这是因为排序后，\"and Ana\"位于字符串的最前面，按照partial_ratio()的处理被忽略掉了（排在末尾也是一样的）。\n",
    "\n",
    "## 含有重复元素的匹配\n",
    "\n",
    "假设有人在数据录入出现了重复，类似\"Tom Tom and Jerry\"这样的错误，我们可用fuzz.token_set_ratio()解决。\n",
    "\n",
    "```language-python\n",
    "str1 = \"Tom and Jerry\"\n",
    "str2 = \"Tom Tom and Jerry\"\n",
    "\n",
    "print (fuzz.ratio(str1, str2))\n",
    "# 87\n",
    "print (fuzz.token_set_ratio(str1, str2))\n",
    "# 100\n",
    "1234567\n",
    "```\n",
    "\n",
    "\n",
    "除此以外，token_set_ratio()还有更多用途。我们之前讲的token_sort_ratio()，是先token化，再排序，最后匹配。而token_set_ratio()在排序的同时还会把字符串分为共有部分（intersection）和多余部分，如下：\n",
    "\n",
    "```language-python\n",
    "# 这一步除了token化、分离、排序外，还会删除字符串中重复的token\n",
    "inter = [sorted_intersection]\n",
    "sorted_str1 = [sorted_intersection] + [sorted_rest_of_str1]\n",
    "sorted_str2 = [sorted_intersection] + [sorted_rest_of_str2]\n",
    "\n",
    "ratio1 = fuzz.ratio(inter, str1)\n",
    "ratio2 = fuzz.ratio(inter,str2)\n",
    "ratio3 = fuzz.ratio(str1, str2)\n",
    "12345678\n",
    "```\n",
    "\n",
    "\n",
    "再在ratio1, ratio2, ratio3三个值之中简单取最大值。\n",
    "\n",
    "来看实例，假设我们现在有两个人同时输入Donald Trump，但其中一个人输入了全名\"Donald J. Trump\"，而另一个人不小心多按了一次ctrl+v，输入了\"Donald TrumpDonald Trump\". 这个例子中并没有重复的单词，那么token_set_ratio()处理效果如何呢？\n",
    "\n",
    "```language-python\n",
    "str1 = \"Donald J. Trump\"\n",
    "str2 = \"Donald TrumpDonald Trump\"\n",
    "\n",
    "# token化，删除重复值，排序\n",
    "inter = \"donald trump\" \n",
    "sorted_str1 = \"donald trump j\"  # j后面的标点被忽视了\n",
    "sortrd_str2 = \"donald trump trumpdonald\"\n",
    "\n",
    "# 两两匹配，取最大值\n",
    "print (fuzz.ratio(inter, sorted_str1))\n",
    "# 92\n",
    "print (fuzz.ratio(inter, sorted_str2))\n",
    "# 67\n",
    "print (fuzz.ratio(sorted_str1, sorted_str2))\n",
    "# 68\n",
    "\n",
    "print (fuzz.token_set_ratio(str1, str2))\n",
    "# 92\n",
    "123456789101112131415161718\n",
    "```\n",
    "\n",
    "\n",
    "可以看到，token_set_ratio()在这几个条件下匹配分会较高：  \n",
    "（1）共有部分在其中一个字符串所占比例很大，那么ratio1或ratio2得分会高；  \n",
    "（2）两个字符串多余的部分十分接近，那么ratio3得分会高。\n",
    "\n",
    "## 总结\n",
    "\n",
    "总的来说，fuzz这几个ratio()函数比较笨，需要人工判断字符串自身的情况，再选择相应的函数匹配。如果选错了，会得到和预想差别很大的结果。前面例子中就有很多匹配结果不理想的。\n",
    "\n",
    "另外fuzzywuzzy还有process模块，用于处理备选答案有限的情况。比如某个问题的答案只有[yes, no, maybe, N/A]几种可能，而答案可能出现\"ya\", \"none\"等，可以使用process.extract()方法，去匹配备选项中最接近的那一个。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 135kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/lw/anaconda3/lib/python3.6/site-packages (from python-Levenshtein) (41.6.0)\n",
      "Building wheels for collected packages: python-Levenshtein\n",
      "  Running setup.py bdist_wheel for python-Levenshtein ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/lw/Library/Caches/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
      "Successfully built python-Levenshtein\n",
      "Installing collected packages: python-Levenshtein\n",
      "Successfully installed python-Levenshtein-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "7\n",
      "0.9523809523809523\n",
      "0.9523809523809523\n",
      "0.7727272727272727\n",
      "0.9682539682539683\n",
      "0.9841269841269842\n",
      "0.8151023694501954\n",
      "0.9968253968253968\n",
      "0.9888888888888889\n",
      "0.8151023694501954\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "query_str = 'as of date 11/12/2019'\n",
    "s1 = 'as of data 11/12/2019'\n",
    "s2 = 'as fo date 11/12/2019'\n",
    "s3 = 'similar date 11/12/2019'\n",
    "\n",
    "# hamming距离，str1和str2长度必须一致，描述两个等长字串之间对应位置上不同字符的个数 \n",
    "print(Levenshtein.hamming(query_str, s1)) # 1 \n",
    "print(Levenshtein.hamming(query_str, s2)) # 2 \n",
    "#print(Levenshtein.hamming(query_str, s3)) #ValueError: hamming expected two unicodes of the same length \n",
    "\n",
    "# 编辑距离，描述由一个字串转化成另一个字串最少的操作次数，在其中的操作包括 插入、删除、替换 \n",
    "print(Levenshtein.distance(query_str, s1)) # 1 \n",
    "print(Levenshtein.distance(query_str, s2)) # 2 \n",
    "print(Levenshtein.distance(query_str, s3)) # 7 \n",
    "\n",
    "# 计算莱文斯坦比 \n",
    "print(Levenshtein.ratio(query_str, s1)) # 0.9523809523809523 \n",
    "print(Levenshtein.ratio(query_str, s2)) # 0.9523809523809523 \n",
    "print(Levenshtein.ratio(query_str, s3)) # 0.7727272727272727 \n",
    "\n",
    "# 计算jaro距离 \n",
    "print(Levenshtein.jaro(query_str, s1)) # 0.9682539682539683 \n",
    "print(Levenshtein.jaro(query_str, s2)) # 0.9841269841269842 \n",
    "print(Levenshtein.jaro(query_str, s3)) # 0.8151023694501954 \n",
    "\n",
    "# Jaro–Winkler距离 \n",
    "print(Levenshtein.jaro_winkler(query_str, s1)) # 0.9968253968253968 \n",
    "print(Levenshtein.jaro_winkler(query_str, s2)) # 0.9888888888888889 \n",
    "print(Levenshtein.jaro_winkler(query_str, s3)) # 0.8151023694501954"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Python实现了常用的字符串相似度算法，一共超过十种。列举如下：\n",
    "\n",
    "* Levenshtein\n",
    "* NormalizedLevenshtein\n",
    "* WeightedLevenshtein\n",
    "* DamerauLevenshtein\n",
    "* OptimalStringAlignment\n",
    "* Jarowinkler\n",
    "* LongestCommonSubsequence\n",
    "* MetricLongestCommonSubsequence\n",
    "* NGram\n",
    "* QGram\n",
    "* Cosine\n",
    "* Jaccard\n",
    "* SorenceDice\n",
    "\n",
    "https://github.com/luozhouyang/python-string-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://zhuanlan.zhihu.com/p/108803219"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
