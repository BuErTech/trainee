{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.opencv.org/2.4/doc/tutorials/imgproc/histograms/template_matching/template_matching.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/007S8ZIlly1ghdk3d7siyj30s00a941t.jpg)\n",
    "\n",
    "本篇文章介绍使用Python和OpenCV对图像进行模板匹配和识别。模板匹配是在图像中寻找和识别模板的一种简单的方法。以下是具体的步骤及代码。\n",
    "\n",
    "首先导入所需库文件，numpy和cv2。\n",
    "\n",
    "\n",
    "\n",
    "Read more: http://bluewhale.cc/2017-09-22/use-python-opencv-for-image-template-matching-match-template.html#ixzz6U1vqsRCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入所需库文件 \n",
    "import cv2 \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后加载原始图像和要搜索的图像模板。OpenCV对原始图像进行处理，创建一个灰度版本，在灰度图像里进行处理和查找匹配。然后使用相同的坐标在原始图像中进行还原并输出。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载原始RGB图像\n",
    "img_rgb = cv2.imread(\"IMG_20200724_094127的副本.jpg\")\n",
    "#创建一个原始图像的灰度版本，所有操作在灰度版本中处理，然后在RGB图像中使用相同坐标还原\n",
    "img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "#加载将要搜索的图像模板\n",
    "template = cv2.imread('WX20200803-132839@2x.png',0)\n",
    "#记录图像模板的尺寸\n",
    "w, h = template.shape[::-1]\n",
    "# 这里我们分别输出并查看原始图像，原始图像的灰度版本，以及图像模板。\n",
    "#查看三组图像(图像标签名称，文件名称)\n",
    "cv2.imshow('rgb',img_rgb)\n",
    "cv2.imshow('gray',img_gray)\n",
    "cv2.imshow('template',template)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# 使用matchTemplate在原始图像中查找并匹配图像模板中的内容，并设置阈值。\n",
    "#使用matchTemplate对原始灰度图像和图像模板进行匹配\n",
    "res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)\n",
    "#设定阈值\n",
    "threshold = 0.7\n",
    "#res大于70%\n",
    "loc = np.where( res >= threshold)\n",
    "# 匹配完成后在原始图像中使用灰度图像的坐标对原始图像进行标记。\n",
    "#使用灰度图像中的坐标对原始RGB图像进行标记\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (7,249,151), 2)\n",
    "#显示图像    \n",
    "cv2.imshow('Detected',img_rgb)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 137\n",
      "(array([598, 598, 598, 599]), array([197, 198, 199, 198]))\n"
     ]
    }
   ],
   "source": [
    "# https://www.geeksforgeeks.org/template-matching-using-opencv-in-python/\n",
    "def mathc_img(image,Target,value):\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    \n",
    "    img_rgb = cv2.imread(image)\n",
    "    \n",
    "    \n",
    "    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    template = cv2.imread(Target,0)\n",
    "    w, h = template.shape[::-1]\n",
    "    \n",
    "    print(w,h)\n",
    "    \n",
    "    res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)\n",
    "    threshold = value\n",
    "    loc = np.where( res >= threshold)\n",
    "    \n",
    "    print(loc)\n",
    "    \n",
    "    \n",
    "    for pt in zip(*loc[::-1]):\n",
    "        cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (7,249,151), 2) \n",
    "        # cv2.rectangle(image, 左下角坐标, 右上角坐标, color, 线条粗度)\n",
    "    cv2.imshow('Detected',img_rgb)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "image=(\"IMG_20200724_094127.jpg\")\n",
    "# Target=('WX20200803-132839@2x.png')\n",
    "Target=('IMG_20200724_094127_TARGET.jpg')\n",
    "value=0.9\n",
    "mathc_img(image,Target,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/94/46dcae8c061e28be31bcaa55c560cb30ee9403c9a4bb2659768ec1b9eb7d/imutils-0.5.3.tar.gz\n",
      "Building wheels for collected packages: imutils\n",
      "  Running setup.py bdist_wheel for imutils ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/lw/Library/Caches/pip/wheels/16/84/1f/bf88641293cda2c8be81a5c4b8ca973dd9125a6dc3767417fd\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils\n",
    "\n",
    "# https://github.com/jrosebr1/imutilsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to illustrate  \n",
    "# multiscaling in template matching \n",
    "import cv2 \n",
    "import numpy as np \n",
    "import imutils\n",
    "   \n",
    "# Read the main image \n",
    "img_rgb = cv2.imread('IMG_20200724_094127.jpg') \n",
    "   \n",
    "# Convert to grayscale \n",
    "img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY) \n",
    "   \n",
    "# Read the template \n",
    "template = cv2.imread('WX20200803-132839@2x.png',0) \n",
    "   \n",
    "# Store width and height of template in w and h \n",
    "w, h = template.shape[::-1] \n",
    "found = None\n",
    "  \n",
    "for scale in np.linspace(0.2, 1.0, 20)[::-1]: \n",
    "  \n",
    "    # resize the image according to the scale, and keep track \n",
    "    # of the ratio of the resizing \n",
    "    # https://github.com/jrosebr1/imutils\n",
    "    resized = imutils.resize(img_gray, width = int(img_gray.shape[1] * scale)) \n",
    "    r = img_gray.shape[1] / float(resized.shape[1]) \n",
    "   \n",
    "    # if the resized image is smaller than the template, then break \n",
    "    # from the loop \n",
    "    # detect edges in the resized, grayscale image and apply template  \n",
    "    # matching to find the template in the image edged  \n",
    "    # = cv2.Canny(resized, 50, 200) result = cv2.matchTemplate(edged, template, \n",
    "    # cv2.TM_CCOEFF) (_, maxVal, _, maxLoc) = cv2.minMaxLoc(result) \n",
    "    # if we have found a new maximum correlation value, then update \n",
    "    # the found variable if found is None or maxVal > found[0]: \n",
    "    \n",
    "    edged = cv2.Canny(resized, 50, 200) \n",
    "    result = cv2.matchTemplate(edged, template, cv2.TM_CCOEFF) \n",
    "    (_, maxVal, _, maxLoc) = cv2.minMaxLoc(result) \n",
    "    if resized.shape[0] < h or resized.shape[1] < w: \n",
    "            break\n",
    "    found = (maxVal, maxLoc, r) \n",
    "   \n",
    "# unpack the found varaible and compute the (x, y) coordinates \n",
    "# of the bounding box based on the resized ratio \n",
    "(_, maxLoc, r) = found \n",
    "(startX, startY) = (int(maxLoc[0] * r), int(maxLoc[1] * r)) \n",
    "(endX, endY) = (int((maxLoc[0] + w) * r), int((maxLoc[1] + h) * r)) \n",
    "  \n",
    "# draw a bounding box around the detected result and display the image \n",
    "cv2.rectangle(img_rgb, (startX, startY), (endX, endY), (0, 0, 255), 2) \n",
    "cv2.imshow(\"Image\", image) \n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.jianshu.com/p/53ef74b02f6a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def translate(image, x, y):\n",
    "\t# Define the translation matrix and perform the translation\n",
    "\tM = np.float32([[1, 0, x], [0, 1, y]])\n",
    "\tshifted = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "\t# Return the translated image\n",
    "\treturn shifted\n",
    "\n",
    "def rotate(image, angle, center = None, scale = 1.0):\n",
    "\t# Grab the dimensions of the image\n",
    "\t(h, w) = image.shape[:2]\n",
    "\n",
    "\t# If the center is None, initialize it as the center of\n",
    "\t# the image\n",
    "\tif center is None:\n",
    "\t\tcenter = (w / 2, h / 2)\n",
    "\n",
    "\t# Perform the rotation\n",
    "\tM = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "\trotated = cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "\t# Return the rotated image\n",
    "\treturn rotated\n",
    "\n",
    "def resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "\t# initialize the dimensions of the image to be resized and\n",
    "\t# grab the image size\n",
    "\tdim = None\n",
    "\t(h, w) = image.shape[:2]\n",
    "\n",
    "\t# if both the width and height are None, then return the\n",
    "\t# original image\n",
    "\tif width is None and height is None:\n",
    "\t\treturn image\n",
    "\n",
    "\t# check to see if the width is None\n",
    "\tif width is None:\n",
    "\t\t# calculate the ratio of the height and construct the\n",
    "\t\t# dimensions\n",
    "\t\tr = height / float(h)\n",
    "\t\tdim = (int(w * r), height)\n",
    "\n",
    "\t# otherwise, the height is None\n",
    "\telse:\n",
    "\t\t# calculate the ratio of the width and construct the\n",
    "\t\t# dimensions\n",
    "\t\tr = width / float(w)\n",
    "\t\tdim = (width, int(h * r))\n",
    "\n",
    "\t# resize the image\n",
    "\tresized = cv2.resize(image, dim, interpolation = inter)\n",
    "\n",
    "\t# return the resized image\n",
    "\treturn resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.pyimagesearch.com/2015/01/26/multi-scale-template-matching-using-python-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images/IMG_20200724_094127.jpg\n",
      "Current Scale5.0\n",
      "Current Scale4.747368421052632\n",
      "Current Scale4.494736842105263\n",
      "Current Scale4.242105263157895\n",
      "Current Scale3.9894736842105267\n",
      "Current Scale3.7368421052631584\n",
      "Current Scale3.4842105263157896\n",
      "Current Scale3.2315789473684213\n",
      "Current Scale2.978947368421053\n",
      "Current Scale2.7263157894736842\n",
      "Current Scale2.473684210526316\n",
      "Current Scale2.2210526315789476\n",
      "Current Scale1.968421052631579\n",
      "Current Scale1.7157894736842105\n",
      "Current Scale1.463157894736842\n",
      "Current Scale1.2105263157894737\n",
      "Current Scale0.9578947368421054\n",
      "Current Scale0.7052631578947368\n",
      "Current Scale0.45263157894736844\n",
      "Current Scale0.2\n"
     ]
    }
   ],
   "source": [
    "# USAGE\n",
    "# python match.py --template cod_logo.png --images images\n",
    "\n",
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "templateIMG = \"WX20200803-132839@2x.png\"\n",
    "\n",
    "# load the image image, convert it to grayscale, and detect edges\n",
    "template = cv2.imread(templateIMG)\n",
    "template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "template = cv2.Canny(template, 50, 200)\n",
    "(tH, tW) = template.shape[:2]\n",
    "cv2.imshow(\"Template\", template)\n",
    "images = \"./images/\"\n",
    "# loop over the images to find the template in\n",
    "for imagePath in glob.glob(images + \"/*.jpg\"):\n",
    "\tprint(imagePath)\n",
    "\t# load the image, convert it to grayscale, and initialize the\n",
    "\t# bookkeeping variable to keep track of the matched region\n",
    "\timage = cv2.imread(imagePath)\n",
    "\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\tfound = None\n",
    "\n",
    "\t# loop over the scales of the image\n",
    "\tfor scale in np.linspace(0.2, 5.0, 20)[::-1]:\n",
    "\t\tprint(\"Current Scale\"+str(scale))\n",
    "\t\t# resize the image according to the scale, and keep track\n",
    "\t\t# of the ratio of the resizing\n",
    "\t\tresized = imutils.resize(gray, width = int(gray.shape[1] * scale))\n",
    "\t\tr = gray.shape[1] / float(resized.shape[1])\n",
    "\n",
    "\t\t# if the resized image is smaller than the template, then break\n",
    "\t\t# from the loop\n",
    "\t\tif resized.shape[0] < tH or resized.shape[1] < tW:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\t# detect edges in the resized, grayscale image and apply template\n",
    "\t\t# matching to find the template in the image\n",
    "\t\tedged = cv2.Canny(resized, 50, 200)\n",
    "\t\tresult = cv2.matchTemplate(edged, template, cv2.TM_CCOEFF)\n",
    "\t\t(_, maxVal, _, maxLoc) = cv2.minMaxLoc(result)\n",
    "\n",
    "\t\t# check to see if the iteration should be visualized\n",
    "# \t\tif True:\n",
    "# \t\t\t# draw a bounding box around the detected region\n",
    "# \t\t\tclone = np.dstack([edged, edged, edged])\n",
    "# \t\t\tcv2.rectangle(clone, (maxLoc[0], maxLoc[1]),\n",
    "# \t\t\t\t(maxLoc[0] + tW, maxLoc[1] + tH), (0, 0, 255), 2)\n",
    "# \t\t\tcv2.imshow(\"Visualize\", clone)\n",
    "# \t\t\tcv2.waitKey(0)\n",
    "\n",
    "\t\t# if we have found a new maximum correlation value, then ipdate\n",
    "\t\t# the bookkeeping variable\n",
    "\t\tif found is None or maxVal > found[0]:\n",
    "\t\t\tfound = (maxVal, maxLoc, r)\n",
    "\n",
    "\t# unpack the bookkeeping varaible and compute the (x, y) coordinates\n",
    "\t# of the bounding box based on the resized ratio\n",
    "\t(_, maxLoc, r) = found\n",
    "\t(startX, startY) = (int(maxLoc[0] * r), int(maxLoc[1] * r))\n",
    "\t(endX, endY) = (int((maxLoc[0] + tW) * r), int((maxLoc[1] + tH) * r))\n",
    "\n",
    "\t# draw a bounding box around the detected result and display the image\n",
    "\tcv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "\tcv2.imshow(\"Image\", image)\n",
    "\tcv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
